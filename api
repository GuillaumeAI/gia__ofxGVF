 
//==================================
// DECLARATION
//==================================

ofxGVF gvf;


//==================================
// CONSTRUCT GVF
//==================================

gvf.setup(parameters, coefficents);

    where 
        - parameters: structure ofxGVFParameters with fields
            - inputDimensions
            – numberParticles
            – tolerance
            – resamplingThreshold
            – distribution

        - coefficients: structure ofxGVFVarianceCoefficients with fields
            - phaseVariance
            – speedVariance
            – scaleVariance
            – rotationVariance


//==================================
// SWITCHING MODES: LEARNING, FOLLOWING, CLEAR
//==================================

gvf.setState( Mode );

    where mode is: ofxGVF::STATE_LEARNING or ofxGVF::STATE_FOLLOWING or ofxGVF::STATE_CLEAR

Mode = gvf.getState();


//==================================
// LEARNING a GESTURE
//==================================

ofxGVFGesture currentGesture;

currentGesture.clear();

    clear only for the first point of the gesture

currentGesture.setAutoAdjustRanges(false);
currentGesture.setMin(0.0f, 0.0f);
currentGesture.setMax(ofGetWidth(), ofGetHeight());

    define auto normalization for drawing purposes only at the starting point of the gesture

currentGesture.addObservationRaw(ofPoint(x, y, 0));

    where x, y are 2-dimensional gesture coordinate (e.g. from the mouse). this is called for
    each new point to put in the gesture

gvf.addGestureTemplate(currentGesture);

    at the end of the gesture, just add the gesture as a template to GVF


//==================================
// RECOGNITION & VARIATION FOLLOWING
//==================================

gvf.spreadParticles();

    only for the first point

gvf.infer();


//==================================
// GETTING RECOGNIZED GESTURE AND VARIATION ESTIMATIONS
//==================================

vector<vector<float> > gvfEstimates = gvf.getEstimatedStatus();



